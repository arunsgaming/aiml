{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "1. CrossValidation and Sampling.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea6WoZ4hw-ld"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUtcs7How-lg"
      },
      "source": [
        "data = pd.read_csv(\"iris.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlgbIDYYw-lg"
      },
      "source": [
        "features = data.iloc[:,:-1].values\n",
        "label = data.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuUdkAEfw-lh"
      },
      "source": [
        "# Cross Validation Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhKhbSHLw-lh"
      },
      "source": [
        "### Goal:\n",
        "1. To get the minimum score threshold\n",
        "2. To understand what optimal score I can achieve from the dataset\n",
        "3. To extract the best training sample that can give the best score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jqNfXE2w-lh"
      },
      "source": [
        "# Demonstrate the score threshold with LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelAlgo = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUu4W5_fw-li",
        "outputId": "badec489-38f8-464c-f3af-5753a3c9e12f"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Supress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "scores = cross_val_score(modelAlgo,\n",
        "                        features,\n",
        "                        label,\n",
        "                        cv = 10) #5 or 10\n",
        "\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.93333333, 1.        , 1.        , 0.93333333,\n",
              "       0.93333333, 0.93333333, 1.        , 1.        , 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v7YXUFRw-lj",
        "outputId": "13ad6e3c-cd77-4e81-edaf-cf8e6a8b9754"
      },
      "source": [
        "# What is the minimum score threshold for this dataset?\n",
        "\n",
        "print(\"Minimum Score Threshold is : \",scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum Score Threshold is :  0.9733333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRGk6ecdw-lj"
      },
      "source": [
        "# LogisticR : Threshold: 0.9733333333333334"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZyInIrrw-lk",
        "outputId": "9d1141c3-e071-4b48-f4eb-beb2dfc1c941"
      },
      "source": [
        "# What is the optimal score I can achieve for this dataset using LogisticRegression?\n",
        "scores.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdA8RG2Uw-lk",
        "outputId": "00d7ea61-acb5-432c-9d37-dc709f99edf9"
      },
      "source": [
        "# 3. To extract the best training sample that gives the best score for LogisticRegression\n",
        "\n",
        "# Step1: Initialize the algo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelAlgo = LogisticRegression()\n",
        "\n",
        "# Step2: Initialize K-Fold Cross Validation function\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=10, #Use the same CV values that was applied in cross_val_score\n",
        "             shuffle=True,\n",
        "             random_state = 1) # To ensure the data is not randomized at every iteration\n",
        "\n",
        "# 3. initialize for loop to identify which sample gives the best score and which sample is the best \n",
        "#.   training sample\n",
        "\n",
        "counter = 0\n",
        "\n",
        "for train,test in kfold.split(features):\n",
        "    \n",
        "    #Counter will help you track the sample split\n",
        "    counter += 1\n",
        "    \n",
        "    #Extract the training set and testing set\n",
        "    X_train,X_test = features[train],features[test]\n",
        "    y_train,y_test = label[train] , label[test]\n",
        "    \n",
        "    #Fit the model \n",
        "    modelAlgo.fit(X_train,y_train)\n",
        "    \n",
        "    if modelAlgo.score(X_test,y_test) >= 1.0:\n",
        "        print(\"Test Score {} Train Score {} for Sample Split {}\".format(modelAlgo.score(X_test,y_test),modelAlgo.score(X_train,y_train),counter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score 1.0 Train Score 0.9777777777777777 for Sample Split 1\n",
            "Test Score 1.0 Train Score 0.9777777777777777 for Sample Split 4\n",
            "Test Score 1.0 Train Score 0.9703703703703703 for Sample Split 7\n",
            "Test Score 1.0 Train Score 0.9703703703703703 for Sample Split 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIeKhn0rw-ll"
      },
      "source": [
        "# Extract the samples\n",
        "# Step1: Initialize the algo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelAlgo = LogisticRegression()\n",
        "\n",
        "# Step2: Initialize K-Fold Cross Validation function\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=10, #Use the same CV values that was applied in cross_val_score\n",
        "             shuffle=True,\n",
        "             random_state = 1) # To ensure the data is not randomized at every iteration\n",
        "\n",
        "# 3. initialize for loop to identify which sample gives the best score and which sample is the best \n",
        "#.   training sample\n",
        "\n",
        "counter = 0\n",
        "for train,test in kfold.split(features):\n",
        "    \n",
        "    #Counter will help you track the sample split\n",
        "    counter += 1\n",
        "    \n",
        "    if counter == 1:\n",
        "        X_train,X_test,y_train,y_test = features[train],features[test],label[train] , label[test]\n",
        "    \n",
        " \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkayaBusw-ll",
        "outputId": "0abc0219-6b9c-4ece-fb12-f1944d2d9ae8"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "finalModel = LogisticRegression()\n",
        "finalModel.fit(X_train,y_train)\n",
        "finalModel.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QwMT8i5w-lm",
        "outputId": "59d0ec2b-b34b-4e04-859e-7d2268aa4a9f"
      },
      "source": [
        "# Another method to extract best sample (Optimized Way --> Dealing with Large Data in less time)\n",
        "# StraifiedShuffleSplit\n",
        "# 3. To extract the best training sample that gives the best score for LogisticRegression\n",
        "\n",
        "# Step1: Initialize the algo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelAlgo = LogisticRegression()\n",
        "\n",
        "# Step2: Initialize StratifiedShuffleSplit Cross Validation function\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "ss = StratifiedShuffleSplit(n_splits=10, #Use the same CV values that was applied in cross_val_score\n",
        "             test_size=0.2,\n",
        "             random_state = 1) # To ensure the data is not randomized at every iteration\n",
        "\n",
        "# 3. initialize for loop to identify which sample gives the best score and which sample is the best \n",
        "#.   training sample\n",
        "\n",
        "counter = 0\n",
        "\n",
        "for train,test in ss.split(features,label):\n",
        "    \n",
        "    #Counter will help you track the sample split\n",
        "    counter += 1\n",
        "    \n",
        "    #Extract the training set and testing set\n",
        "    X_train,X_test = features[train],features[test]\n",
        "    y_train,y_test = label[train] , label[test]\n",
        "    \n",
        "    #Fit the model \n",
        "    modelAlgo.fit(X_train,y_train)\n",
        "    \n",
        "    if modelAlgo.score(X_test,y_test) >= 1.0:\n",
        "        print(\"Test Score {} Train Score {} for Sample Split {}\".format(modelAlgo.score(X_test,y_test),modelAlgo.score(X_train,y_train),counter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score 1.0 Train Score 0.9666666666666667 for Sample Split 3\n",
            "Test Score 1.0 Train Score 0.975 for Sample Split 7\n",
            "Test Score 1.0 Train Score 0.9583333333333334 for Sample Split 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Wf4PBIw-lm"
      },
      "source": [
        "# Extract the samples\n",
        "# Step1: Initialize the algo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelAlgo = LogisticRegression()\n",
        "\n",
        "# Step2: Initialize K-Fold Cross Validation function\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "ss = StratifiedShuffleSplit(n_splits=10, #Use the same CV values that was applied in cross_val_score\n",
        "             test_size=0.2,\n",
        "             random_state = 1) # To ensure the data is not randomized at every iteration\n",
        "\n",
        "# 3. initialize for loop to identify which sample gives the best score and which sample is the best \n",
        "#.   training sample\n",
        "\n",
        "counter = 0\n",
        "for train,test in ss.split(features,label):\n",
        "    \n",
        "    #Counter will help you track the sample split\n",
        "    counter += 1\n",
        "    \n",
        "    if counter == 7:\n",
        "        X_trainSS,X_testSS,y_trainSS,y_testSS = features[train],features[test],label[train] , label[test]\n",
        "    \n",
        " \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yaPmp4Uw-ln",
        "outputId": "bb359dd9-5d3a-4269-f828-f1c8a46d0e6d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "finalModel = LogisticRegression()\n",
        "finalModel.fit(X_trainSS,y_trainSS)\n",
        "finalModel.score(X_testSS,y_testSS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuuhzuAuw-ln"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}